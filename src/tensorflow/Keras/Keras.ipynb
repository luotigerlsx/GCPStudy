{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=keras.regularizers.l1(0.01))\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x121121fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Model.compile takes three important arguments:\n",
    "\n",
    "* optimizer: This object specifies the training procedure. Pass it optimizer instances from the tf.train module, such as AdamOptimizer, RMSPropOptimizer, or GradientDescentOptimizer.\n",
    "* loss: The function to minimize during optimization. Common choices include mean square error (mse), categorical_crossentropy, and binary_crossentropy. Loss functions are specified by name or by passing a callable object from the tf.keras.losses module.\n",
    "* metrics: Used to monitor training. These are string names or callables from the tf.keras.metrics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=[keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.randint(low = 1, high=10, size=(1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.randint(low = 1, high=10, size=(100, 10))\n",
    "\n",
    "# model.fit(data, labels, epochs=10, batch_size=32,\n",
    "#           validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 114.6922 - categorical_accuracy: 0.1010 - val_loss: 116.2324 - val_categorical_accuracy: 0.1354\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 114.6473 - categorical_accuracy: 0.1083 - val_loss: 116.0136 - val_categorical_accuracy: 0.0521\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 114.4130 - categorical_accuracy: 0.1094 - val_loss: 113.1709 - val_categorical_accuracy: 0.1042\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 114.3887 - categorical_accuracy: 0.1240 - val_loss: 117.0150 - val_categorical_accuracy: 0.0938\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 114.4329 - categorical_accuracy: 0.1156 - val_loss: 116.2336 - val_categorical_accuracy: 0.1146\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 114.1415 - categorical_accuracy: 0.1115 - val_loss: 115.9885 - val_categorical_accuracy: 0.1771\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 114.4246 - categorical_accuracy: 0.1125 - val_loss: 113.1597 - val_categorical_accuracy: 0.1146\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 114.4373 - categorical_accuracy: 0.0969 - val_loss: 117.0794 - val_categorical_accuracy: 0.0417\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 114.1968 - categorical_accuracy: 0.1125 - val_loss: 116.2391 - val_categorical_accuracy: 0.0625\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 114.0577 - categorical_accuracy: 0.1063 - val_loss: 115.9795 - val_categorical_accuracy: 0.1667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x120e69978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[114.34282353719075, 0.13229166666666667]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funtional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBuilding a model with the functional API works like this:\\n\\n1. A layer instance is callable and returns a tensor.\\n2. Input tensors and output tensors are used to define a tf.keras.Model instance.\\n3. This model is trained just like the Sequential model.\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Building a model with the functional API works like this:\n",
    "\n",
    "1. A layer instance is callable and returns a tensor.\n",
    "2. Input tensors and output tensors are used to define a tf.keras.Model instance.\n",
    "3. This model is trained just like the Sequential model.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 247us/step - loss: 115.0030 - acc: 0.1030\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 114.6100 - acc: 0.1030\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 114.5181 - acc: 0.1160\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 114.4268 - acc: 0.1200\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 114.3877 - acc: 0.1310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12148ef98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32,))  # Returns a placeholder tensor\n",
    "\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Instantiate the model given inputs and outputs.\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize Model and Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 225us/step - loss: 115.2690 - acc: 0.1130\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 114.6835 - acc: 0.1150\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 114.5927 - acc: 0.1120\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 114.5263 - acc: 0.1020\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 114.4817 - acc: 0.1110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12144ab70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        # Define your layers here.\n",
    "        self.dense_1 = keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define your forward pass here,\n",
    "        # using layers you previously defined (in `__init__`).\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # You need to override this function if you want to use the subclassed model\n",
    "        # as part of a functional-style model.\n",
    "        # Otherwise, this method is optional.\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "\n",
    "# Instantiates the subclassed model.\n",
    "model = MyModel(num_classes=10)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 193us/step - loss: 126.8104 - acc: 0.1150\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 121.0607 - acc: 0.1040\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 118.9924 - acc: 0.0950\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 118.2887 - acc: 0.0960\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 118.0103 - acc: 0.0880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12281c6d8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLayer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        # Be sure to call this at the end\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "# Create a model using the custom layer\n",
    "model = keras.Sequential([MyLayer(10),\n",
    "                          keras.layers.Activation('softmax')])\n",
    "\n",
    "# The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "A callback is an object passed to a model to customize and extend its behavior during training. You can write your own custom callback, or use the built-in tf.keras.callbacks that include:\n",
    "\n",
    "* tf.keras.callbacks.ModelCheckpoint: Save checkpoints of your model at regular intervals.\n",
    "* tf.keras.callbacks.LearningRateScheduler: Dynamically change the learning rate.\n",
    "* tf.keras.callbacks.EarlyStopping: Interrupt training when validation performance has stopped improving.\n",
    "* tf.keras.callbacks.TensorBoard: Monitor the model's behavior using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(val_data, val_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution\n",
    "A tf.keras.Model can be trained with the tf.estimator API by converting the model to an tf.estimator.Estimator object with tf.keras.estimator.model_to_estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(10,)))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.2)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    x = np.random.random((1024, 10))\n",
    "    y = np.random.randint(2, size=(1024, 1))\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.repeat(10)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = tf.contrib.distribute.MirroredStrategy()\n",
    "# config = tf.estimator.RunConfig(train_distribute=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('/tmp/model_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_service': None, '_log_step_count_steps': 100, '_train_distribute': None, '_save_checkpoints_steps': None, '_is_chief': True, '_global_id_in_cluster': 0, '_evaluation_master': '', '_task_id': 0, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_task_type': 'worker', '_num_worker_replicas': 1, '_device_fn': None, '_session_config': None, '_model_dir': '/tmp/model_dir', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x128139ef0>, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_num_ps_replicas': 0}\n"
     ]
    }
   ],
   "source": [
    "keras_estimator = keras.estimator.model_to_estimator(\n",
    "  keras_model=model,\n",
    "#   config=config,\n",
    "  model_dir='/tmp/model_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model_dir/keras_model.ckpt\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/model_dir/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.73264664, step = 2\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /tmp/model_dir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.6661602.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x12810ff98>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_estimator.train(input_fn=input_fn, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense_10/bias',\n",
       " 'dense_10/kernel',\n",
       " 'dense_11/bias',\n",
       " 'dense_11/kernel',\n",
       " 'global_step']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_estimator.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
