{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data_plus_bias_scaled = StandardScaler().fit_transform(housing_data_plus_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_Model:\n",
    "    def __init__(self, mode):\n",
    "        self._build_graph(mode)\n",
    "    \n",
    "    def _build_graph(self, mode='train'):\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
    "        self.y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "        theta = tf.get_variable(name='theta', shape=(n+1, 1), dtype=tf.float32)\n",
    "\n",
    "        y_pred = tf.matmul(X, theta, name='predictions')\n",
    "        error = y_pred - y\n",
    "        if mode == 'train':\n",
    "            mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "            training_op = optimizer.minimize(mse)\n",
    "            tf.summary.scalar(\"cost_function\", mse)\n",
    "            self.train_op = training_op\n",
    "        else:\n",
    "            \n",
    "            loss = tf.reduce_mean(error, name='loss')\n",
    "            self.loss = loss\n",
    "            \n",
    "        self.merged = tf.summary.merge_all()\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        self.saver = saver\n",
    "            \n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_data_plus_bias_scaled.astype(np.float32)\n",
    "y = housing.target.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = housing_data_plus_bias_scaled[indices] # not shown\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_epochs = 10\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('root'):\n",
    "    train_model = LR_Model('train')\n",
    "    initializer = tf.global_variables_initializer()\n",
    "\n",
    "with tf.variable_scope('root', reuse=True):\n",
    "    eval_model = LR_Model('eval')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(initializer)\n",
    "    train_writer = tf.summary.FileWriter('/Users/luoshixin/Downloads/graph', sess.graph)\n",
    "    train_writer.add_graph(tf.get_default_graph())\n",
    "    i = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            i += 1\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            _, summary = sess.run([train_model.train_op, train_model.merged], \n",
    "                              feed_dict={train_model.X: X_batch, train_model.y: y_batch})\n",
    "#             train_writer.add_summary(summary, i)\n",
    "            \n",
    "        sess.run([eval_model.loss], feed_dict={eval_model.X: X_batch, eval_model.y: y_batch})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
